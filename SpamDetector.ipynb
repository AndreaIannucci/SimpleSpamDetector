{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tarfile\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Sklearn library for metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Sklearn library for preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Bag of words vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the spam tar.bz2 file and create a new directory containing the spam archive\n",
    "tar = tarfile.open(\"./data/20021010_spam.tar.bz2\", \"r:bz2\")  \n",
    "tar.extractall(\"./data/spam_data\")\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ham tar.bz2 file and create a new direcoty containing the ham archive\n",
    "tar = tarfile.open(\"./data/20021010_hard_ham.tar.bz2\", \"r:bz2\")  \n",
    "tar.extractall(\"./data/ham_data\")\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(path):\n",
    "    \"\"\"Get the text of every mail in a given directory.\"\"\"\n",
    "    texts = []\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        with open(os.path.join(path, file), encoding='utf8', errors='ignore') as f:\n",
    "            content = f.read()\n",
    "            try:\n",
    "                soup = BeautifulSoup(content, 'html.parser')\n",
    "                content = soup.get_text()\n",
    "            except:\n",
    "                pass\n",
    "        texts.append(content)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text from every document in spam\n",
    "spam_path = './data/spam_data/spam'\n",
    "spam_content = get_text(spam_path)\n",
    "\n",
    "# Get text from every document in ham\n",
    "ham_path = './data/ham_data/hard_ham'\n",
    "ham_content = get_text(ham_path)\n",
    "\n",
    "# Since there are just 250 ham elements let's choose just a \n",
    "spam_columns = 200\n",
    "data = spam_content[0:spam_columns] + ham_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bag', CountVectorizer()),\n",
    "    ('frequencies', TfidfTransformer())\n",
    "])\n",
    "\n",
    "data = pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450,) (450, 33706)\n"
     ]
    }
   ],
   "source": [
    "# Generate the labels before shuffling and splitting the data\n",
    "labels = np.array([0 for _ in range(0, 200)] + [1 for _ in range(0, 250)])\n",
    "print(labels.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_neighbors': 3, 'weights': 'distance'},\n",
       " {'mean_fit_time': array([0.00778604, 0.0078156 , 0.        , 0.00781512, 0.        ,\n",
       "         0.        ]),\n",
       "  'mean_score_time': array([0.00779068, 0.00783014, 0.01564562, 0.00781345, 0.01560843,\n",
       "         0.0078156 ]),\n",
       "  'mean_test_score': array([0.90277778, 0.91388889, 0.90277778, 0.91388889, 0.9       ,\n",
       "         0.90833333]),\n",
       "  'mean_train_score': array([0.975     , 1.        , 0.94722222, 1.        , 0.94166667,\n",
       "         1.        ]),\n",
       "  'param_n_neighbors': masked_array(data=[3, 3, 4, 4, 5, 5],\n",
       "               mask=[False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                     'uniform', 'distance'],\n",
       "               mask=[False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'n_neighbors': 3, 'weights': 'uniform'},\n",
       "   {'n_neighbors': 3, 'weights': 'distance'},\n",
       "   {'n_neighbors': 4, 'weights': 'uniform'},\n",
       "   {'n_neighbors': 4, 'weights': 'distance'},\n",
       "   {'n_neighbors': 5, 'weights': 'uniform'},\n",
       "   {'n_neighbors': 5, 'weights': 'distance'}],\n",
       "  'rank_test_score': array([4, 1, 4, 1, 6, 3]),\n",
       "  'split0_test_score': array([0.9       , 0.91111111, 0.90555556, 0.90555556, 0.91111111,\n",
       "         0.91666667]),\n",
       "  'split0_train_score': array([0.95555556, 1.        , 0.95      , 1.        , 0.93333333,\n",
       "         1.        ]),\n",
       "  'split1_test_score': array([0.90555556, 0.91666667, 0.9       , 0.92222222, 0.88888889,\n",
       "         0.9       ]),\n",
       "  'split1_train_score': array([0.99444444, 1.        , 0.94444444, 1.        , 0.95      ,\n",
       "         1.        ]),\n",
       "  'std_fit_time': array([0.00778604, 0.0078156 , 0.        , 0.00781512, 0.        ,\n",
       "         0.        ]),\n",
       "  'std_score_time': array([7.79068470e-03, 7.83014297e-03, 1.96695328e-05, 7.81345367e-03,\n",
       "         1.84774399e-05, 7.81559944e-03]),\n",
       "  'std_test_score': array([0.00277778, 0.00277778, 0.00277778, 0.00833333, 0.01111111,\n",
       "         0.00833333]),\n",
       "  'std_train_score': array([0.01944444, 0.        , 0.00277778, 0.        , 0.00833333,\n",
       "         0.        ])})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use grid search to choose the best parameters for the model\n",
    "params = {\n",
    "    'n_neighbors':[3, 4, 5],\n",
    "    'weights':['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# For the classification a KNN model will be used\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "grid = GridSearchCV(KNN, params, cv=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "grid.best_params_, grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score --> 0.9444444444444444\n",
      "Confusion Matrix --> [[30  2]\n",
      " [ 3 55]]\n"
     ]
    }
   ],
   "source": [
    "# Train and test the classifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict = clf.predict(X_test)\n",
    "conf_mx = confusion_matrix(y_test, predict)\n",
    "\n",
    "print('Score --> {}'.format(accuracy_score(y_test, predict)))\n",
    "print('Confusion Matrix --> {}'.format(conf_mx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25faa9f19b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the confusion matrix\n",
    "row_sum = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sum\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
